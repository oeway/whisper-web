<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Whisper Transcription</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    @keyframes pulse-ring { 0% { transform: scale(0.9); opacity: 0.8; } 100% { transform: scale(1.3); opacity: 0; } }
    .ring-anim { animation: pulse-ring 1.2s infinite; }
    @keyframes blink-dot { 0%, 100% { opacity: 0.25; } 50% { opacity: 1; } }
    .loading-dot { animation: blink-dot 1s infinite; }
  </style>
</head>
<body class="min-h-screen bg-slate-950 text-slate-50 flex flex-col items-center p-6 gap-8">
  <div class="w-full max-w-3xl bg-slate-900/70 border border-slate-800 rounded-3xl shadow-2xl p-6 space-y-6">
    <div id="authBanner" class="hidden bg-red-900/60 border border-red-700 rounded-xl p-4 text-sm text-red-200">
      <strong>Authentication required.</strong> Pass your Hypha token in the URL: <code class="bg-red-950 px-1 rounded">?token=YOUR_TOKEN</code>
    </div>
    <header class="flex items-center justify-between gap-4">
      <div>
        <p class="text-sm uppercase tracking-[0.25em] text-emerald-300">Whisper</p>
        <h1 class="text-2xl font-semibold">Voice Transcription</h1>
        <p class="text-slate-400 text-sm">VAD-filtered recording with batch transcription</p>
      </div>
      <div class="flex flex-col gap-2 text-sm">
        <select id="modelSelect" class="bg-slate-800 border border-slate-700 rounded-lg px-3 py-2 focus:outline-none focus:ring-2 focus:ring-emerald-400">
          <option value="tiny">Tiny</option>
          <option value="base">Base</option>
          <option value="small" selected>Small</option>
          <option value="medium">Medium</option>
          <option value="large-v3">Large v3</option>
        </select>
        <select id="langSelect" class="bg-slate-800 border border-slate-700 rounded-lg px-3 py-2 focus:outline-none focus:ring-2 focus:ring-emerald-400">
          <option value="auto" selected>Auto language</option>
          <option value="en">English</option>
          <option value="es">Spanish</option>
          <option value="fr">French</option>
          <option value="de">German</option>
          <option value="it">Italian</option>
          <option value="ja">Japanese</option>
          <option value="zh">Chinese</option>
        </select>
      </div>
    </header>

    <div class="flex flex-col md:flex-row gap-6 items-center">
      <button id="micBtn" class="relative isolate w-24 h-24 rounded-full bg-gradient-to-br from-emerald-400 to-cyan-500 text-slate-950 font-semibold shadow-lg flex items-center justify-center transition hover:scale-105 focus:outline-none focus:ring-4 focus:ring-emerald-300/70">
        <div id="micRing" class="absolute inset-0 rounded-full ring-anim opacity-0"></div>
        <svg id="micIcon" xmlns="http://www.w3.org/2000/svg" class="w-10 h-10" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.6" d="M12 1.5v9m0 0a3 3 0 0 1-3-3V6a3 3 0 1 1 6 0v1.5a3 3 0 0 1-3 3Zm0 0v3.75m-5.25-3A5.25 5.25 0 0 0 12 18h0a5.25 5.25 0 0 0 5.25-5.25" /></svg>
        <svg id="stopIcon" xmlns="http://www.w3.org/2000/svg" class="w-10 h-10 hidden" fill="currentColor" viewBox="0 0 24 24"><rect x="6" y="6" width="12" height="12" rx="2" /></svg>
      </button>
      <div class="flex-1 space-y-2">
        <div class="flex items-center gap-2 text-slate-400 text-sm">
          <span class="inline-block w-2 h-2 rounded-full bg-slate-500" id="statusDot"></span>
          <span id="statusText">Click mic to start recording.</span>
        </div>
        <div id="timer" class="text-3xl font-mono text-slate-300 tabular-nums">00:00</div>
        <div id="chunkInfo" class="hidden text-xs font-mono text-slate-500"></div>
        <div id="loadingRow" class="hidden flex items-center gap-1 text-xs text-amber-300">
          <span>Transcribing</span>
          <span class="loading-dot">.</span>
          <span class="loading-dot" style="animation-delay: 0.2s">.</span>
          <span class="loading-dot" style="animation-delay: 0.4s">.</span>
        </div>
      </div>
    </div>

    <div class="bg-slate-900/80 border border-slate-800 rounded-2xl p-4 space-y-3">
      <div class="flex items-center justify-between">
        <p class="text-sm text-slate-400">Transcript</p>
        <div id="stats" class="hidden flex flex-wrap gap-x-4 gap-y-1 text-xs font-mono text-slate-500">
          <span id="statDuration"></span>
          <span id="statChunks"></span>
          <span id="statFileSize"></span>
          <span id="statProcessTime"></span>
          <span id="statModel"></span>
        </div>
      </div>
      <div id="transcript" class="min-h-[160px] leading-relaxed text-lg font-medium text-slate-100 whitespace-pre-wrap"></div>
    </div>

    <div class="bg-slate-900/60 border border-slate-800 rounded-2xl p-4 space-y-2">
      <label class="text-sm text-slate-400" for="prompt">Optional system prompt (sent to Whisper)</label>
      <textarea id="prompt" class="w-full bg-slate-800 border border-slate-700 rounded-xl px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-emerald-400" rows="2" placeholder="e.g. Names: Alice, Bob. Domain: healthcare."></textarea>
    </div>
  </div>

  <!-- Developer SDK Section -->
  <div class="w-full max-w-3xl bg-slate-900/70 border border-slate-800 rounded-3xl shadow-2xl p-6 space-y-4">
    <header>
      <p class="text-sm uppercase tracking-[0.25em] text-cyan-300">Developer</p>
      <h2 class="text-xl font-semibold">SDK Usage</h2>
      <p class="text-slate-400 text-sm">Import <code class="bg-slate-800 px-1.5 py-0.5 rounded text-emerald-300">WhisperClient</code> into your own app — no build step required.</p>
    </header>
    <pre class="bg-slate-950 border border-slate-800 rounded-xl p-4 text-sm text-slate-300 overflow-x-auto"><code><span class="text-cyan-300">import</span> { WhisperClient } <span class="text-cyan-300">from</span> <span class="text-emerald-300">'/whisper-client.js'</span>;

<span class="text-slate-500">// Create a client</span>
<span class="text-cyan-300">const</span> client = <span class="text-cyan-300">new</span> WhisperClient({
  server: window.location.origin,  <span class="text-slate-500">// default: same origin</span>
  token:  <span class="text-emerald-300">'your-hypha-token'</span>,   <span class="text-slate-500">// optional</span>
  model:  <span class="text-emerald-300">'small'</span>,               <span class="text-slate-500">// tiny | base | small | medium | large-v3</span>
});

<span class="text-slate-500">// Option A: Record from microphone with VAD</span>
client.onChunkUploaded = (info) => console.log(info.chunks, info.totalBytes);
<span class="text-cyan-300">await</span> client.startRecording();
<span class="text-cyan-300">const</span> result = <span class="text-cyan-300">await</span> client.stopRecording();
console.log(result.text);

<span class="text-slate-500">// Option B: Transcribe an audio file directly</span>
<span class="text-cyan-300">const</span> result2 = <span class="text-cyan-300">await</span> client.transcribe(audioBlob);

<span class="text-slate-500">// Cleanup when done</span>
client.destroy();</code></pre>
    <p class="text-xs text-slate-500">TypeScript types: <code class="bg-slate-800 px-1.5 py-0.5 rounded">/whisper-client.d.ts</code></p>
  </div>

<script type="module">
import { WhisperClient } from '/whisper-client.js';

// ---- DOM refs ----
const micBtn     = document.getElementById('micBtn');
const micIcon    = document.getElementById('micIcon');
const stopIcon   = document.getElementById('stopIcon');
const micRing    = document.getElementById('micRing');
const statusDot  = document.getElementById('statusDot');
const statusText = document.getElementById('statusText');
const timerEl    = document.getElementById('timer');
const chunkInfo  = document.getElementById('chunkInfo');
const loadingRow = document.getElementById('loadingRow');
const transcriptEl = document.getElementById('transcript');
const modelSelect  = document.getElementById('modelSelect');
const langSelect   = document.getElementById('langSelect');
const promptInput  = document.getElementById('prompt');
const statsEl        = document.getElementById('stats');
const statDuration   = document.getElementById('statDuration');
const statChunks     = document.getElementById('statChunks');
const statFileSize   = document.getElementById('statFileSize');
const statProcessTime = document.getElementById('statProcessTime');
const statModel      = document.getElementById('statModel');
const authBanner = document.getElementById('authBanner');

const urlToken = new URLSearchParams(window.location.search).get('token') || '';

// ---- SDK client ----
const client = new WhisperClient({
  token: urlToken,
  model: modelSelect.value,
  language: langSelect.value,
  prompt: promptInput.value,
});

// ---- Auth check on load ----
(async () => {
  try {
    const data = await client.getHealth();
    if (data.auth_required && !urlToken) {
      authBanner.classList.remove('hidden');
      micBtn.disabled = true;
      micBtn.style.opacity = 0.4;
      statusText.textContent = 'Authentication required to use this service.';
      return;
    }
    if (data.auth_required && urlToken) {
      const testResp = await fetch('/api/session/_auth_check/chunk', {
        method: 'POST',
        headers: urlToken ? { 'Authorization': `Bearer ${urlToken}` } : {},
        body: (() => { const fd = new FormData(); fd.append('chunk', new Blob([new Uint8Array(0)]), 'empty.wav'); return fd; })(),
      });
      if (testResp.status === 401) {
        authBanner.innerHTML = '<strong>Invalid or expired token.</strong> Please provide a valid Hypha token in the URL.';
        authBanner.classList.remove('hidden');
        micBtn.disabled = true;
        micBtn.style.opacity = 0.4;
        statusText.textContent = 'Authentication failed.';
      }
    }
  } catch (_) {}
})();

// ---- State ----
let isTranscribing = false;
let timerInterval = null;
let recordStart = 0;
let recordDurationS = 0;

// ---- UI helpers ----
function setRecordingUI(active) {
  micIcon.classList.toggle('hidden', active);
  stopIcon.classList.toggle('hidden', !active);
  micRing.style.opacity = active ? 0.5 : 0;
  statusDot.style.backgroundColor = active ? '#f87171' : '#64748b';
  micBtn.style.background = active
    ? 'linear-gradient(135deg, #f87171, #ef4444)' : '';
}

function updateTimer() {
  const elapsed = Math.floor((Date.now() - recordStart) / 1000);
  const m = String(Math.floor(elapsed / 60)).padStart(2, '0');
  const s = String(elapsed % 60).padStart(2, '0');
  timerEl.textContent = `${m}:${s}`;
}

function formatBytes(bytes) {
  if (bytes < 1024) return bytes + ' B';
  if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB';
  return (bytes / (1024 * 1024)).toFixed(2) + ' MB';
}

function showStats(data) {
  const dur = recordDurationS.toFixed(1);
  const speed = (recordDurationS / data.processing_time_s).toFixed(1);
  statDuration.textContent = `duration: ${dur}s`;
  statChunks.textContent = `chunks: ${data.chunks}`;
  statFileSize.textContent = `audio: ${formatBytes(data.file_size_bytes)}`;
  statProcessTime.textContent = `transcribe: ${data.processing_time_s.toFixed(2)}s (${speed}x RT)`;
  statModel.textContent = `model: ${data.model}`;
  statsEl.classList.remove('hidden');
}

// ---- Chunk upload callback ----
client.onChunkUploaded = (info) => {
  chunkInfo.classList.remove('hidden');
  chunkInfo.textContent = `${info.chunks} chunks sent · ${formatBytes(info.totalBytes)} uploaded`;
};

// ---- Button ----
micBtn.addEventListener('click', async () => {
  if (isTranscribing) return;

  if (client.recording) {
    // Stop
    clearInterval(timerInterval);
    recordDurationS = (Date.now() - recordStart) / 1000;
    setRecordingUI(false);

    if (client._chunksSent === 0 && client._pcmLength === 0) {
      statusText.textContent = 'No speech detected. Try again.';
    }

    isTranscribing = true;
    micBtn.disabled = true;
    micBtn.style.opacity = 0.5;
    statusText.textContent = 'Transcribing...';
    loadingRow.classList.remove('hidden');

    try {
      const result = await client.stopRecording();
      if (result.text) {
        transcriptEl.textContent = result.text;
        showStats(result);
      } else {
        transcriptEl.textContent = '(no speech detected)';
      }
    } catch (e) {
      transcriptEl.textContent = `Error: ${e.message}`;
    } finally {
      isTranscribing = false;
      micBtn.disabled = false;
      micBtn.style.opacity = 1;
      micBtn.style.background = '';
      loadingRow.classList.add('hidden');
      statusText.textContent = 'Done. Click mic to record again.';
      statusDot.style.backgroundColor = '#34d399';
    }
  } else {
    // Start — sync options from UI before starting
    client.model = modelSelect.value;
    client.language = langSelect.value;
    client.prompt = promptInput.value;

    try {
      await client.startRecording();
    } catch (e) {
      statusText.textContent = e.message;
      return;
    }
    recordStart = Date.now();
    timerInterval = setInterval(updateTimer, 500);
    updateTimer();
    setRecordingUI(true);
    statusText.textContent = 'Recording... Click to stop.';
    transcriptEl.textContent = '';
    statsEl.classList.add('hidden');
    chunkInfo.classList.add('hidden');
  }
});
</script>
</body>
</html>
