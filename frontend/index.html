<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Whisper Transcription</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    @keyframes pulse-ring { 0% { transform: scale(0.9); opacity: 0.8; } 100% { transform: scale(1.3); opacity: 0; } }
    .ring-anim { animation: pulse-ring 1.2s infinite; }
    @keyframes blink-dot { 0%, 100% { opacity: 0.25; } 50% { opacity: 1; } }
    .loading-dot { animation: blink-dot 1s infinite; }
  </style>
</head>
<body class="min-h-screen bg-slate-950 text-slate-50 flex items-center justify-center p-6">
  <div class="w-full max-w-3xl bg-slate-900/70 border border-slate-800 rounded-3xl shadow-2xl p-6 space-y-6">
    <header class="flex items-center justify-between gap-4">
      <div>
        <p class="text-sm uppercase tracking-[0.25em] text-emerald-300">Whisper</p>
        <h1 class="text-2xl font-semibold">Voice Transcription</h1>
        <p class="text-slate-400 text-sm">VAD-filtered recording with batch transcription</p>
      </div>
      <div class="flex flex-col gap-2 text-sm">
        <select id="modelSelect" class="bg-slate-800 border border-slate-700 rounded-lg px-3 py-2 focus:outline-none focus:ring-2 focus:ring-emerald-400">
          <option value="tiny">Tiny</option>
          <option value="base">Base</option>
          <option value="small" selected>Small</option>
          <option value="medium">Medium</option>
          <option value="large-v3">Large v3</option>
        </select>
        <select id="langSelect" class="bg-slate-800 border border-slate-700 rounded-lg px-3 py-2 focus:outline-none focus:ring-2 focus:ring-emerald-400">
          <option value="auto" selected>Auto language</option>
          <option value="en">English</option>
          <option value="es">Spanish</option>
          <option value="fr">French</option>
          <option value="de">German</option>
          <option value="it">Italian</option>
          <option value="ja">Japanese</option>
          <option value="zh">Chinese</option>
        </select>
      </div>
    </header>

    <div class="flex flex-col md:flex-row gap-6 items-center">
      <button id="micBtn" class="relative isolate w-24 h-24 rounded-full bg-gradient-to-br from-emerald-400 to-cyan-500 text-slate-950 font-semibold shadow-lg flex items-center justify-center transition hover:scale-105 focus:outline-none focus:ring-4 focus:ring-emerald-300/70">
        <div id="micRing" class="absolute inset-0 rounded-full ring-anim opacity-0"></div>
        <svg id="micIcon" xmlns="http://www.w3.org/2000/svg" class="w-10 h-10" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="1.6" d="M12 1.5v9m0 0a3 3 0 0 1-3-3V6a3 3 0 1 1 6 0v1.5a3 3 0 0 1-3 3Zm0 0v3.75m-5.25-3A5.25 5.25 0 0 0 12 18h0a5.25 5.25 0 0 0 5.25-5.25" /></svg>
        <svg id="stopIcon" xmlns="http://www.w3.org/2000/svg" class="w-10 h-10 hidden" fill="currentColor" viewBox="0 0 24 24"><rect x="6" y="6" width="12" height="12" rx="2" /></svg>
      </button>
      <div class="flex-1 space-y-2">
        <div class="flex items-center gap-2 text-slate-400 text-sm">
          <span class="inline-block w-2 h-2 rounded-full bg-slate-500" id="statusDot"></span>
          <span id="statusText">Click mic to start recording.</span>
        </div>
        <div id="timer" class="text-3xl font-mono text-slate-300 tabular-nums">00:00</div>
        <div id="chunkInfo" class="hidden text-xs font-mono text-slate-500"></div>
        <div id="loadingRow" class="hidden flex items-center gap-1 text-xs text-amber-300">
          <span>Transcribing</span>
          <span class="loading-dot">.</span>
          <span class="loading-dot" style="animation-delay: 0.2s">.</span>
          <span class="loading-dot" style="animation-delay: 0.4s">.</span>
        </div>
      </div>
    </div>

    <div class="bg-slate-900/80 border border-slate-800 rounded-2xl p-4 space-y-3">
      <div class="flex items-center justify-between">
        <p class="text-sm text-slate-400">Transcript</p>
        <div id="stats" class="hidden flex flex-wrap gap-x-4 gap-y-1 text-xs font-mono text-slate-500">
          <span id="statDuration"></span>
          <span id="statChunks"></span>
          <span id="statFileSize"></span>
          <span id="statProcessTime"></span>
          <span id="statModel"></span>
        </div>
      </div>
      <div id="transcript" class="min-h-[160px] leading-relaxed text-lg font-medium text-slate-100 whitespace-pre-wrap"></div>
    </div>

    <div class="bg-slate-900/60 border border-slate-800 rounded-2xl p-4 space-y-2">
      <label class="text-sm text-slate-400" for="prompt">Optional system prompt (sent to Whisper)</label>
      <textarea id="prompt" class="w-full bg-slate-800 border border-slate-700 rounded-xl px-3 py-2 text-sm focus:outline-none focus:ring-2 focus:ring-emerald-400" rows="2" placeholder="e.g. Names: Alice, Bob. Domain: healthcare."></textarea>
    </div>
  </div>

<script>
// ---- DOM refs ----
const micBtn     = document.getElementById('micBtn');
const micIcon    = document.getElementById('micIcon');
const stopIcon   = document.getElementById('stopIcon');
const micRing    = document.getElementById('micRing');
const statusDot  = document.getElementById('statusDot');
const statusText = document.getElementById('statusText');
const timerEl    = document.getElementById('timer');
const chunkInfo  = document.getElementById('chunkInfo');
const loadingRow = document.getElementById('loadingRow');
const transcriptEl = document.getElementById('transcript');
const modelSelect  = document.getElementById('modelSelect');
const langSelect   = document.getElementById('langSelect');
const promptInput  = document.getElementById('prompt');
const statsEl        = document.getElementById('stats');
const statDuration   = document.getElementById('statDuration');
const statChunks     = document.getElementById('statChunks');
const statFileSize   = document.getElementById('statFileSize');
const statProcessTime = document.getElementById('statProcessTime');
const statModel      = document.getElementById('statModel');

// ---- State ----
let isRecording = false;
let isTranscribing = false;
let sessionId = null;
let mediaStream = null;
let audioCtx = null;
let sourceNode = null;
let processorNode = null;
let chunkTimer = null;
let timerInterval = null;
let recordStart = 0;
let recordDurationS = 0;

// PCM accumulator (between flushes)
let pcmBuffers = [];
let pcmLength = 0;

// VAD state
let speaking = false;
let lastSpeech = 0;
let noiseFloor = 0.004;
let vadWarmupUntil = 0;
let silentStreak = 0;

// Chunk upload tracking
let chunksSent = 0;
let totalBytesSent = 0;

// VAD tuning
const CHUNK_MS = 1500;
const VAD_THRESHOLD = 0.012;
const VAD_HANGOVER_MS = 800;

// ---- UI helpers ----
function setRecordingUI(active) {
  micIcon.classList.toggle('hidden', active);
  stopIcon.classList.toggle('hidden', !active);
  micRing.style.opacity = active ? 0.5 : 0;
  statusDot.style.backgroundColor = active ? '#f87171' : '#64748b';
  micBtn.style.background = active
    ? 'linear-gradient(135deg, #f87171, #ef4444)' : '';
}

function updateTimer() {
  const elapsed = Math.floor((Date.now() - recordStart) / 1000);
  const m = String(Math.floor(elapsed / 60)).padStart(2, '0');
  const s = String(elapsed % 60).padStart(2, '0');
  timerEl.textContent = `${m}:${s}`;
}

function updateChunkInfo() {
  chunkInfo.classList.remove('hidden');
  chunkInfo.textContent = `${chunksSent} chunks sent · ${formatBytes(totalBytesSent)} uploaded`;
}

function formatBytes(bytes) {
  if (bytes < 1024) return bytes + ' B';
  if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB';
  return (bytes / (1024 * 1024)).toFixed(2) + ' MB';
}

// ---- WAV encoding ----
function encodeWav(samples, sampleRate) {
  const bytesPerSample = 2;
  const dataSize = samples.length * bytesPerSample;
  const buffer = new ArrayBuffer(44 + dataSize);
  const v = new DataView(buffer);
  const w = (off, str) => { for (let i = 0; i < str.length; i++) v.setUint8(off + i, str.charCodeAt(i)); };
  w(0, 'RIFF');
  v.setUint32(4, 36 + dataSize, true);
  w(8, 'WAVE');
  w(12, 'fmt ');
  v.setUint32(16, 16, true);
  v.setUint16(20, 1, true);
  v.setUint16(22, 1, true);
  v.setUint32(24, sampleRate, true);
  v.setUint32(28, sampleRate * bytesPerSample, true);
  v.setUint16(32, bytesPerSample, true);
  v.setUint16(34, 16, true);
  w(36, 'data');
  v.setUint32(40, dataSize, true);
  for (let i = 0; i < samples.length; i++) {
    const s = Math.max(-1, Math.min(1, samples[i]));
    v.setInt16(44 + i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
  }
  return new Blob([v], { type: 'audio/wav' });
}

function mergeBuffers(buffers, length) {
  const out = new Float32Array(length);
  let off = 0;
  for (const b of buffers) { out.set(b, off); off += b.length; }
  return out;
}

// ---- Chunk flushing with VAD ----
async function flushChunk(force = false) {
  if (pcmLength === 0 || !audioCtx) return;
  const now = performance.now();
  const inWarmup = now < vadWarmupUntil;
  const active = force || inWarmup || speaking || (now - lastSpeech < VAD_HANGOVER_MS);

  const merged = mergeBuffers(pcmBuffers, pcmLength);
  pcmBuffers = [];
  pcmLength = 0;

  if (!active) {
    silentStreak += 1;
    return; // skip silent chunk
  }
  silentStreak = 0;

  const wavBlob = encodeWav(merged, audioCtx.sampleRate);
  if (wavBlob.size < 1200) return; // too tiny

  // Upload chunk to session buffer on backend
  const form = new FormData();
  form.append('chunk', wavBlob, 'chunk.wav');
  try {
    const resp = await fetch(`/api/session/${sessionId}/chunk`, { method: 'POST', body: form });
    if (resp.ok) {
      chunksSent += 1;
      totalBytesSent += wavBlob.size;
      updateChunkInfo();
    }
  } catch (e) {
    // Network error — non-fatal, chunk is lost but recording continues
  }
}

// ---- Recording ----
async function startRecording() {
  if (!navigator.mediaDevices?.getUserMedia) {
    statusText.textContent = 'Mic not available in this browser.';
    return;
  }
  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
  } catch (e) {
    statusText.textContent = 'Mic permission denied.';
    return;
  }

  sessionId = crypto.randomUUID();
  chunksSent = 0;
  totalBytesSent = 0;

  audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  sourceNode = audioCtx.createMediaStreamSource(mediaStream);
  processorNode = audioCtx.createScriptProcessor(4096, 1, 1);
  const muteNode = audioCtx.createGain();
  muteNode.gain.value = 0;
  sourceNode.connect(processorNode);
  processorNode.connect(muteNode);
  muteNode.connect(audioCtx.destination);
  await audioCtx.resume();

  pcmBuffers = [];
  pcmLength = 0;
  speaking = false;
  lastSpeech = 0;
  noiseFloor = 0.004;
  silentStreak = 0;
  vadWarmupUntil = performance.now() + 3000; // send first 3s unconditionally

  processorNode.onaudioprocess = (e) => {
    if (!isRecording) return;
    const input = e.inputBuffer.getChannelData(0);

    // VAD: compute RMS and update adaptive noise floor
    let sum = 0;
    for (let i = 0; i < input.length; i++) { sum += input[i] * input[i]; }
    const rms = Math.sqrt(sum / input.length);
    noiseFloor = 0.97 * noiseFloor + 0.03 * Math.min(rms, noiseFloor * 3);
    const threshold = Math.max(VAD_THRESHOLD * 0.35, noiseFloor * 2.2);
    speaking = rms > threshold;
    if (speaking) lastSpeech = performance.now();

    const copy = new Float32Array(input.length);
    copy.set(input);
    pcmBuffers.push(copy);
    pcmLength += copy.length;
  };

  // Flush chunks periodically
  chunkTimer = setInterval(() => flushChunk(false), CHUNK_MS);

  isRecording = true;
  recordStart = Date.now();
  timerInterval = setInterval(updateTimer, 500);
  updateTimer();
  setRecordingUI(true);
  statusText.textContent = 'Recording... Click to stop.';
  transcriptEl.textContent = '';
  statsEl.classList.add('hidden');
  chunkInfo.classList.add('hidden');
}

async function stopRecording() {
  isRecording = false;
  clearInterval(timerInterval);
  clearInterval(chunkTimer);
  recordDurationS = (Date.now() - recordStart) / 1000;

  // Flush any remaining audio
  if (pcmLength > 0 && audioCtx) {
    await flushChunk(true);
  }

  if (processorNode) processorNode.disconnect();
  if (sourceNode) sourceNode.disconnect();
  if (mediaStream) mediaStream.getTracks().forEach(t => t.stop());
  if (audioCtx) { audioCtx.close(); audioCtx = null; }

  setRecordingUI(false);

  if (chunksSent === 0) {
    statusText.textContent = 'No speech detected. Try again.';
    return;
  }

  // Trigger server-side transcription of all accumulated chunks
  await transcribeSession();
}

async function transcribeSession() {
  isTranscribing = true;
  micBtn.disabled = true;
  micBtn.style.opacity = 0.5;
  statusText.textContent = 'Transcribing...';
  loadingRow.classList.remove('hidden');

  const params = new URLSearchParams({
    model_size: modelSelect.value,
    language: langSelect.value,
    prompt: promptInput.value,
  });

  try {
    const resp = await fetch(`/api/session/${sessionId}/transcribe?${params}`, { method: 'POST' });
    if (!resp.ok) {
      const err = await resp.text();
      transcriptEl.textContent = `Error: ${err}`;
    } else {
      const data = await resp.json();
      transcriptEl.textContent = data.text || '(no speech detected)';
      showStats(data);
    }
  } catch (e) {
    transcriptEl.textContent = `Network error: ${e.message}`;
  } finally {
    isTranscribing = false;
    micBtn.disabled = false;
    micBtn.style.opacity = 1;
    micBtn.style.background = '';
    loadingRow.classList.add('hidden');
    statusText.textContent = 'Done. Click mic to record again.';
    statusDot.style.backgroundColor = '#34d399';
  }
}

function showStats(data) {
  const dur = recordDurationS.toFixed(1);
  const speed = (recordDurationS / data.processing_time_s).toFixed(1);
  statDuration.textContent = `duration: ${dur}s`;
  statChunks.textContent = `chunks: ${data.chunks}`;
  statFileSize.textContent = `audio: ${formatBytes(data.file_size_bytes)}`;
  statProcessTime.textContent = `transcribe: ${data.processing_time_s.toFixed(2)}s (${speed}x RT)`;
  statModel.textContent = `model: ${data.model}`;
  statsEl.classList.remove('hidden');
}

// ---- Button ----
micBtn.addEventListener('click', () => {
  if (isTranscribing) return;
  if (isRecording) {
    stopRecording();
  } else {
    startRecording();
  }
});
</script>
</body>
</html>
